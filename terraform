Terraform 1.14.5
After Running 'terraform init'   <--- This initializes the working directory and sets up the backend.
.terraform/ (Directory)          <--- Stores provider plugins, modules, and backend configuration.
.terraform.lock.hcl (File)       <--- Locks provider versions to ensure consistency across environments.
terraform.tfstate (only if a remote backend is configured during init) <--- Stores the current state of the infrastructure.
After Running 'terraform apply'  <--- This command applies the changes and manages infrastructure.
terraform.tfstate (File)         <--- Stores the current state of the deployed infrastructure.
terraform.tfstate.backup (File)  <--- A backup of the previous state file.
planfile (if used with terraform apply planfile) <-- Applied execution plan (can be deleted after use).

Why Use 'data' in Terraform?
Does not create resources,only reads existing ones.To fetch existing resources (e.g., an existing VPC, IAM role, or image).
To avoid hardcoding values and make configurations more dynamic.
To reference resources created outside of Terraform.

terraform/
‚îÇ‚îÄ‚îÄ main.tf          # Calls the module
‚îÇ‚îÄ‚îÄ variables.tf     # Input variables
‚îÇ‚îÄ‚îÄ outputs.tf       # Outputs
‚îÇ‚îÄ‚îÄ modules/
‚îÇ   ‚îú‚îÄ‚îÄ vm/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ main.tf  # VM definition
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ variables.tf
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ outputs.tf


Execute terraform module by module
----------------------------------
##sample
terraform plan -target=module.module_instances.google_compute_region_instance_group_manager.ig_esserver
terraform apply -target=module.module_instances.google_compute_region_instance_group_manager.ig_esserver

terraform init     <--Initializes the Terraform working directory (downloads providers, modules, etc.)
terraform validate <--Checks if configuration files are syntactically valid
terraform validate -json <-- Outputs validation in JSON (for automation)
terraform plan     <--Previews changes Terraform will make (no changes applied yet)
terraform apply    <--Applies the planned changes (asks for confirmation)
terraform apply -auto-approve  <--Applies changes without asking for confirmation
terraform apply -var="region=us-east1"  <-- Overrides variable value from CLI eg:terraform apply -var="project=myproject"
terraform apply -var-file="prod.tfvars" <-- Loads variables from a file eg:terraform apply -var-file="prod.tfvars"
terraform plan -lock=false <--runs the plan without acquiring a state lock
terraform force-unlock -force IDcanbeshowninlockerror
terraform destroy       <-- Destroys all managed infrastructure
terraform plan destroy  <-- Destroys without confirmation
terraform refresh       <-- Updates the state file to match real infrastructure
terraform output        <-- Displays output values from state
terraform output <name> <-- Shows a specific output value eg:terraform output instance_ip
terraform taint google_compute_instance.vm_instance <-- to tell Terraform to recreate the instance.
terraform show         <--Displays the current state or plan in human-readable format
terraform state list   <--Lists all resources in the current state
terraform state show <resource> <--Shows details for a specific resource eg:terraform state show aws_instance.my_vm
terraform state rm <resource> <--Removes a resource from state (won‚Äôt destroy it). eg:terraform state rm google_compute_instance.myvm
terraform workspace  list     <-- Lists all workspaces
terraform workspace new <name> <-- Creates a new workspace
terraform workspace  show <--Shows the current workspace
terraform workspace select <name> <--Switches to a workspace
terraform import         <-- command is used to import existing resources into Terraform.
terraform fmt            <-- Formats .tf files to canonical style. it cleans up spacing, alignment, and indentation so that your .tf files look consistent and professional.
terraform fmt -recursive <-- Formats all .tf files in subdirectories
terraform providers      <-- Shows all providers used
terraform providers schema <-- Displays available arguments and attributes for providers
terraform providers lock <-- Locks provider versions for reproducibility
terraform get            <-- Download new modules or update missing ones
terraform get -update    <-- Force re-download of all modules, even if already present
terraform version        <-- Shows Terraform version
terraform graph          <-- Generates a visual dependency graph (in DOT format)
terraform console        <-- Opens an interactive console to query variables, outputs, etc.
terraform login          <-- Authenticates to Terraform Cloud
##### Instance without autoscalar
resource "google_compute_instance" "instance_name"
resource "google_compute_address" "globalip_of_instance"
##### Instance with autosclaer
resource "google_compute_region_autoscaler" "autoscaler_apserver"
resource "google_compute_region_instance_group_manager" "instancegroup_apserver"
resource "google_compute_instance_template" "template_apserver"
resource "google_compute_health_check" "hc_apserver"
#### Loadbalancer
resource "google_compute_global_forwarding_rule" "forwardingrule_aplb"
resource "google_dns_record_set" "dns_aplb"
resource "google_compute_global_address" "globalip_aplb"
resource "google_compute_target_https_proxy" "target_httpsproxy_aplb"
resource "google_compute_managed_ssl_certificate" "certificate_aplb"
resource "google_compute_url_map" "lb_apserver_urlmap"
resource "google_compute_backend_service" "backend_aplb"
resource "google_compute_health_check" "healthcheck_aplb"
##### Network
resource "google_compute_network" "vpc_name"
resource "google_compute_subnetwork" "subnet_name"
resource "google_compute_global_address" "subnet_private"
resource "google_service_networking_connection" "private_service_connection"
#####DB
resource "google_sql_database_instance" "deabase_instance_name"
resource "google_sql_database" "databasename"
resource "google_sql_user" "database_username"
#####Firewall
resource "google_compute_firewall" "allow_fm_bastion"

#####GKE###########
resource "google_container_cluster" "cluster1"
resource "google_container_node_pool" "pools"
------------------------------------------------------------------------------------------------------------------------------------
Here's a Terraform script to create an AWS EKS Cluster with a managed node group. It includes:

‚úÖ VPC and Subnets
‚úÖ EKS Cluster
‚úÖ Node Group
‚úÖ IAM Roles and Policies

üìú Terraform Code for AWS EKS Cluster
provider "aws" {
  region = "us-west-2"
}

# üöÄ Create VPC
resource "aws_vpc" "eks_vpc" {
  cidr_block = "10.0.0.0/16"

  tags = {
    Name = "eks-vpc"
  }
}

# üöÄ Create Subnets
resource "aws_subnet" "eks_subnet_a" {
  vpc_id            = aws_vpc.eks_vpc.id
  cidr_block        = "10.0.1.0/24"
  availability_zone = "us-west-2a"

  tags = {
    Name = "eks-subnet-a"
  }
}

resource "aws_subnet" "eks_subnet_b" {
  vpc_id            = aws_vpc.eks_vpc.id
  cidr_block        = "10.0.2.0/24"
  availability_zone = "us-west-2b"

  tags = {
    Name = "eks-subnet-b"
  }
}

# üöÄ Create IAM Role for EKS Cluster
resource "aws_iam_role" "eks_cluster_role" {
  name = "eks-cluster-role"

  assume_role_policy = jsonencode({
    Version = "2012-10-17"
    Statement = [{
      Effect = "Allow"
      Principal = {
        Service = "eks.amazonaws.com"
      }
      Action = "sts:AssumeRole"
    }]
  })
}

# üöÄ Attach Policies to EKS IAM Role
resource "aws_iam_role_policy_attachment" "eks_cluster_policy" {
  role       = aws_iam_role.eks_cluster_role.name
  policy_arn = "arn:aws:iam::aws:policy/AmazonEKSClusterPolicy"
}

# üöÄ Create EKS Cluster
resource "aws_eks_cluster" "eks" {
  name     = "my-eks-cluster"
  role_arn = aws_iam_role.eks_cluster_role.arn

  vpc_config {
    subnet_ids = [aws_subnet.eks_subnet_a.id, aws_subnet.eks_subnet_b.id]
  }

  depends_on = [aws_iam_role_policy_attachment.eks_cluster_policy]
}

# üöÄ Create IAM Role for Worker Nodes
resource "aws_iam_role" "eks_node_role" {
  name = "eks-node-role"

  assume_role_policy = jsonencode({
    Version = "2012-10-17"
    Statement = [{
      Effect = "Allow"
      Principal = {
        Service = "ec2.amazonaws.com"
      }
      Action = "sts:AssumeRole"
    }]
  })
}

# üöÄ Attach Policies to Worker Node IAM Role
resource "aws_iam_role_policy_attachment" "eks_worker_node_policy" {
  role       = aws_iam_role.eks_node_role.name
  policy_arn = "arn:aws:iam::aws:policy/AmazonEKSWorkerNodePolicy"
}

resource "aws_iam_role_policy_attachment" "eks_cni_policy" {
  role       = aws_iam_role.eks_node_role.name
  policy_arn = "arn:aws:iam::aws:policy/AmazonEKS_CNI_Policy"
}

resource "aws_iam_role_policy_attachment" "eks_ec2_readonly" {
  role       = aws_iam_role.eks_node_role.name
  policy_arn = "arn:aws:iam::aws:policy/AmazonEC2ContainerRegistryReadOnly"
}

# üöÄ Create EKS Managed Node Group
resource "aws_eks_node_group" "eks_nodes" {
  cluster_name    = aws_eks_cluster.eks.name
  node_group_name = "eks-node-group"
  node_role_arn   = aws_iam_role.eks_node_role.arn
  subnet_ids      = [aws_subnet.eks_subnet_a.id, aws_subnet.eks_subnet_b.id]

  scaling_config {
    desired_size = 2
    max_size     = 3
    min_size     = 1
  }

  instance_types = ["t3.medium"]

  depends_on = [
    aws_iam_role_policy_attachment.eks_worker_node_policy,
    aws_iam_role_policy_attachment.eks_cni_policy,
    aws_iam_role_policy_attachment.eks_ec2_readonly
  ]
}

# üöÄ Output Cluster Details
output "cluster_endpoint" {
  value = aws_eks_cluster.eks.endpoint
}

output "cluster_name" {
  value = aws_eks_cluster.eks.name
}
üöÄ How to Use This Terraform Code
1Ô∏è‚É£ Initialize Terraform
terraform init

2Ô∏è‚É£ Plan the Deployment
terraform plan

3Ô∏è‚É£ Apply to Create the EKS Cluster
terraform apply -auto-approve

4Ô∏è‚É£ Configure kubectl to Connect to EKS
aws eks update-kubeconfig --region us-west-2 --name my-eks-cluster

5Ô∏è‚É£ Verify the Cluster
kubectl get nodes

üõë How to Destroy the EKS Cluster
If you want to delete everything:
terraform destroy -auto-approve

------------------------------------------------------------------------------------------------------------------------------------
azurerm       <--It is the provider used in Terraform to manage Azure resources. The azurerm provider allows Terraform to provision 
                 and configure Azure infrastructure components such as Virtual Machines, Storage, Networking, and more.

Terraform Code for Azure VM
provider "azurerm" {
  features {}
}

# Define Resource Group
resource "azurerm_resource_group" "rg" {
  name     = "myResourceGroup"
  location = "East US"
}

# Define Virtual Network
resource "azurerm_virtual_network" "vnet" {
  name                = "myVNet"
  location            = azurerm_resource_group.rg.location
  resource_group_name = azurerm_resource_group.rg.name
  address_space       = ["10.0.0.0/16"]
}

# Define Subnet
resource "azurerm_subnet" "subnet" {
  name                 = "mySubnet"
  resource_group_name  = azurerm_resource_group.rg.name
  virtual_network_name = azurerm_virtual_network.vnet.name
  address_prefixes     = ["10.0.1.0/24"]
}

# Define Public IP
resource "azurerm_public_ip" "public_ip" {
  name                = "myPublicIP"
  location            = azurerm_resource_group.rg.location
  resource_group_name = azurerm_resource_group.rg.name
  allocation_method   = "Dynamic"
}

# Define Network Interface
resource "azurerm_network_interface" "nic" {
  name                = "myNIC"
  location            = azurerm_resource_group.rg.location
  resource_group_name = azurerm_resource_group.rg.name

  ip_configuration {
    name                          = "internal"
    subnet_id                     = azurerm_subnet.subnet.id
    private_ip_address_allocation = "Dynamic"
    public_ip_address_id          = azurerm_public_ip.public_ip.id
  }
}

# Define Virtual Machine
resource "azurerm_windows_virtual_machine" "vm" {
  name                = "myVM"
  resource_group_name = azurerm_resource_group.rg.name
  location            = azurerm_resource_group.rg.location
  size                = "Standard_B1s"
  admin_username      = "adminuser"
  admin_password      = "P@ssword1234!"  # Change this or use a secure method

  network_interface_ids = [azurerm_network_interface.nic.id]

  os_disk {
    caching              = "ReadWrite"
    storage_account_type = "Standard_LRS"
  }

  source_image_reference {
    publisher = "MicrosoftWindowsServer"
    offer     = "WindowsServer"
    sku       = "2019-Datacenter"
    version   = "latest"
  }
}

# Output Public IP
output "vm_public_ip" {
  value = azurerm_public_ip.public_ip.ip_address
}
-----------------
Data: In Terraform, the data block is used to fetch existing Azure resources, or derive dynamic values instead of creating new ones

Fetch an Existing Resource Group:
data "azurerm_resource_group" "existing_rg" {
  name = "MyExistingResourceGroup"
}
output "rg_location" {
  value = data.azurerm_resource_group.existing_rg.location
}

Get an Existing Virtual Network:
data "azurerm_virtual_network" "existing_vnet" {
  name                = "MyVNet"
  resource_group_name = "MyExistingResourceGroup"
}
output "vnet_address_space" {
  value = data.azurerm_virtual_network.existing_vnet.address_space
}

Get Available VM Sizes in a Region:
data "azurerm_compute_vm_sizes" "available_sizes" {
  location = "East US"
}
output "vm_sizes" {
  value = data.azurerm_compute_vm_sizes.available_sizes.sizes
}

Get an Existing Storage Account:
data "azurerm_storage_account" "existing_storage" {
  name                = "mystorageaccount"
  resource_group_name = "MyExistingResourceGroup"
}
output "storage_primary_endpoint" {
  value = data.azurerm_storage_account.existing_storage.primary_blob_endpoint
}
--------------------------------------------------------------------------------------------------------------
GCP
production-style sample Terraform code for GCP including:

‚úÖ provider
‚úÖ data sources
‚úÖ VPC
‚úÖ subnet
‚úÖ compute instance

This is the minimum complete working example.

üìå Terraform Folder Structure
terraform-gcp/
 ‚îú‚îÄ‚îÄ main.tf
 ‚îú‚îÄ‚îÄ variables.tf
 ‚îú‚îÄ‚îÄ outputs.tf
 ‚îî‚îÄ‚îÄ terraform.tfvars

üß± main.tf
terraform {
  required_version = ">= 1.5.0"

  required_providers {
    google = {
      source  = "hashicorp/google"
      version = ">= 5.0.0"
    }
  }
}
provider "google" {
  project = "my-project"
  region  = "asia-south1"
  zone    = "asia-south1-a"
}

provider "google-beta" {
  project = "my-project"
  region  = "asia-south1"
  zone    = "asia-south1-a"
}

# -----------------------------
# Data Source (Get project info)
# -----------------------------
data "google_project" "project" {
  project_id = var.project_id
}

# -----------------------------
# VPC Network
# -----------------------------
resource "google_compute_network" "vpc_network" {
  name                    = "my-vpc"
  auto_create_subnetworks = false
}

# -----------------------------
# Subnetwork
# -----------------------------
resource "google_compute_subnetwork" "subnet" {
  name          = "my-subnet"
  ip_cidr_range = "10.10.0.0/24"
  region        = var.region
  network       = google_compute_network.vpc_network.self_link
}

# -----------------------------
# Firewall (Allow SSH)
# -----------------------------
resource "google_compute_firewall" "allow_ssh" {
  name    = "allow-ssh"
  network = google_compute_network.vpc_network.name

  allow {
    protocol = "tcp"
    ports    = ["22"]
  }

  source_ranges = ["0.0.0.0/0"]
}

# -----------------------------
# Compute Instance
# -----------------------------
resource "google_compute_instance" "vm" {
  name         = "my-vm"
  machine_type = "e2-medium"
  zone         = var.zone

  boot_disk {
    initialize_params {
      image = "debian-cloud/debian-12"
    }
  }

  network_interface {
    subnetwork = google_compute_subnetwork.subnet.id

    access_config {
      # Ephemeral public IP
    }
  }

  metadata = {
    ssh-keys = "admin:${file(var.public_key_path)}"
  }

  tags = ["ssh"]
}

‚öôÔ∏è variables.tf
variable "project_id" {
  type        = string
  description = "GCP Project ID"
}

variable "region" {
  type        = string
  default     = "asia-south1"
}

variable "zone" {
  type        = string
  default     = "asia-south1-a"
}

variable "public_key_path" {
  type        = string
  description = "Path to SSH public key"
  default     = "~/.ssh/id_rsa.pub"
}

üì§ outputs.tf
output "vm_public_ip" {
  description = "Public IP of the compute instance"
  value       = google_compute_instance.vm.network_interface[0].access_config[0].nat_ip
}

output "vpc_name" {
  value = google_compute_network.vpc_network.name
}

output "subnet_name" {
  value = google_compute_subnetwork.subnet.name
}

üìù terraform.tfvars
project_id       = "your-gcp-project-id"
region           = "asia-south1"
zone             = "asia-south1-a"
public_key_path  = "~/.ssh/id_rsa.pub"

üöÄ Commands to Run
terraform init
terraform plan
terraform apply -auto-approve


provider "kubernetes" {
  host                   = google_container_cluster.primary.endpoint
  token                  = data.google_client_config.default.access_token
  cluster_ca_certificate = base64decode(google_container_cluster.primary.master_auth[0].cluster_ca_certificate)
}

resource "kubernetes_deployment" "app" {
  metadata {
    name = "myapp"
    namespace = "default"
  }

  spec {
    replicas = 2
    selector {
      match_labels = {
        app = "myapp"
      }
    }
    template {
      metadata {
        labels = {
          app = "myapp"
        }
      }
      spec {
        container {
          name  = "myapp"
          image = "nginx"
        }
      }
    }
  }
}
