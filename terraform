After Running 'terraform init'   <--- This initializes the working directory and sets up the backend.
.terraform/ (Directory)          <--- Stores provider plugins, modules, and backend configuration.
.terraform.lock.hcl (File)       <--- Locks provider versions to ensure consistency across environments.
terraform.tfstate (only if a remote backend is configured during init) <--- Stores the current state of the infrastructure.
After Running 'terraform apply'  <--- This command applies the changes and manages infrastructure.
terraform.tfstate (File)         <--- Stores the current state of the deployed infrastructure.
terraform.tfstate.backup (File)  <--- A backup of the previous state file.
planfile (if used with terraform apply planfile) <-- Applied execution plan (can be deleted after use).

Why Use 'data' in Terraform?
Does not create resources,only reads existing ones.To fetch existing resources (e.g., an existing VPC, IAM role, or image).
To avoid hardcoding values and make configurations more dynamic.
To reference resources created outside of Terraform.

terraform/
│── main.tf          # Calls the module
│── variables.tf     # Input variables
│── outputs.tf       # Outputs
│── modules/
│   ├── vm/
│   │   ├── main.tf  # VM definition
│   │   ├── variables.tf
│   │   ├── outputs.tf


Execute terraform module by module
----------------------------------
##sample
terraform plan -target=module.module_instances.google_compute_region_instance_group_manager.ig_esserver
terraform apply -target=module.module_instances.google_compute_region_instance_group_manager.ig_esserver

terraform init
terraform validate
terraform plan
terraform apply
terraform apply -auto-approve
terraform plan -lock=false
terraform force-unlock -force IDcanbeshowninlockerror
terraform plan destroy 
terraform refresh      <--This will refresh your state by comparing it to your cloud infrastructure.
terraform output       <--output command is also useful for scripts to extract outputs from your configuration.
terraform taint google_compute_instance.vm_instance   <-- to tell Terraform to recreate the instance.
terraform show
terraform workspace 
terraform workspace  show
terraform workspace  select
terraform import       <-- command is used to import existing resources into Terraform.

##### Instance without autoscalar
resource "google_compute_instance" "instance_name"
resource "google_compute_address" "globalip_of_instance"
##### Instance with autosclaer
resource "google_compute_region_autoscaler" "autoscaler_apserver"
resource "google_compute_region_instance_group_manager" "instancegroup_apserver"
resource "google_compute_instance_template" "template_apserver"
resource "google_compute_health_check" "hc_apserver"
#### Loadbalancer
resource "google_compute_global_forwarding_rule" "forwardingrule_aplb"
resource "google_dns_record_set" "dns_aplb"
resource "google_compute_global_address" "globalip_aplb"
resource "google_compute_target_https_proxy" "target_httpsproxy_aplb"
resource "google_compute_managed_ssl_certificate" "certificate_aplb"
resource "google_compute_url_map" "lb_apserver_urlmap"
resource "google_compute_backend_service" "backend_aplb"
resource "google_compute_health_check" "healthcheck_aplb"
##### Network
resource "google_compute_network" "vpc_name"
resource "google_compute_subnetwork" "subnet_name"
resource "google_compute_global_address" "subnet_private"
resource "google_service_networking_connection" "private_service_connection"
#####DB
resource "google_sql_database_instance" "deabase_instance_name"
resource "google_sql_database" "databasename"
resource "google_sql_user" "database_username"
#####Firewall
resource "google_compute_firewall" "allow_fm_bastion"

#####GKE###########
resource "google_container_cluster" "cluster1"
resource "google_container_node_pool" "pools"
------------------------------------------------------------------------------------------------------------------------------------
Here's a Terraform script to create an AWS EKS Cluster with a managed node group. It includes:

✅ VPC and Subnets
✅ EKS Cluster
✅ Node Group
✅ IAM Roles and Policies

📜 Terraform Code for AWS EKS Cluster
provider "aws" {
  region = "us-west-2"
}

# 🚀 Create VPC
resource "aws_vpc" "eks_vpc" {
  cidr_block = "10.0.0.0/16"

  tags = {
    Name = "eks-vpc"
  }
}

# 🚀 Create Subnets
resource "aws_subnet" "eks_subnet_a" {
  vpc_id            = aws_vpc.eks_vpc.id
  cidr_block        = "10.0.1.0/24"
  availability_zone = "us-west-2a"

  tags = {
    Name = "eks-subnet-a"
  }
}

resource "aws_subnet" "eks_subnet_b" {
  vpc_id            = aws_vpc.eks_vpc.id
  cidr_block        = "10.0.2.0/24"
  availability_zone = "us-west-2b"

  tags = {
    Name = "eks-subnet-b"
  }
}

# 🚀 Create IAM Role for EKS Cluster
resource "aws_iam_role" "eks_cluster_role" {
  name = "eks-cluster-role"

  assume_role_policy = jsonencode({
    Version = "2012-10-17"
    Statement = [{
      Effect = "Allow"
      Principal = {
        Service = "eks.amazonaws.com"
      }
      Action = "sts:AssumeRole"
    }]
  })
}

# 🚀 Attach Policies to EKS IAM Role
resource "aws_iam_role_policy_attachment" "eks_cluster_policy" {
  role       = aws_iam_role.eks_cluster_role.name
  policy_arn = "arn:aws:iam::aws:policy/AmazonEKSClusterPolicy"
}

# 🚀 Create EKS Cluster
resource "aws_eks_cluster" "eks" {
  name     = "my-eks-cluster"
  role_arn = aws_iam_role.eks_cluster_role.arn

  vpc_config {
    subnet_ids = [aws_subnet.eks_subnet_a.id, aws_subnet.eks_subnet_b.id]
  }

  depends_on = [aws_iam_role_policy_attachment.eks_cluster_policy]
}

# 🚀 Create IAM Role for Worker Nodes
resource "aws_iam_role" "eks_node_role" {
  name = "eks-node-role"

  assume_role_policy = jsonencode({
    Version = "2012-10-17"
    Statement = [{
      Effect = "Allow"
      Principal = {
        Service = "ec2.amazonaws.com"
      }
      Action = "sts:AssumeRole"
    }]
  })
}

# 🚀 Attach Policies to Worker Node IAM Role
resource "aws_iam_role_policy_attachment" "eks_worker_node_policy" {
  role       = aws_iam_role.eks_node_role.name
  policy_arn = "arn:aws:iam::aws:policy/AmazonEKSWorkerNodePolicy"
}

resource "aws_iam_role_policy_attachment" "eks_cni_policy" {
  role       = aws_iam_role.eks_node_role.name
  policy_arn = "arn:aws:iam::aws:policy/AmazonEKS_CNI_Policy"
}

resource "aws_iam_role_policy_attachment" "eks_ec2_readonly" {
  role       = aws_iam_role.eks_node_role.name
  policy_arn = "arn:aws:iam::aws:policy/AmazonEC2ContainerRegistryReadOnly"
}

# 🚀 Create EKS Managed Node Group
resource "aws_eks_node_group" "eks_nodes" {
  cluster_name    = aws_eks_cluster.eks.name
  node_group_name = "eks-node-group"
  node_role_arn   = aws_iam_role.eks_node_role.arn
  subnet_ids      = [aws_subnet.eks_subnet_a.id, aws_subnet.eks_subnet_b.id]

  scaling_config {
    desired_size = 2
    max_size     = 3
    min_size     = 1
  }

  instance_types = ["t3.medium"]

  depends_on = [
    aws_iam_role_policy_attachment.eks_worker_node_policy,
    aws_iam_role_policy_attachment.eks_cni_policy,
    aws_iam_role_policy_attachment.eks_ec2_readonly
  ]
}

# 🚀 Output Cluster Details
output "cluster_endpoint" {
  value = aws_eks_cluster.eks.endpoint
}

output "cluster_name" {
  value = aws_eks_cluster.eks.name
}
🚀 How to Use This Terraform Code
1️⃣ Initialize Terraform
terraform init

2️⃣ Plan the Deployment
terraform plan

3️⃣ Apply to Create the EKS Cluster
terraform apply -auto-approve

4️⃣ Configure kubectl to Connect to EKS
aws eks update-kubeconfig --region us-west-2 --name my-eks-cluster

5️⃣ Verify the Cluster
kubectl get nodes

🛑 How to Destroy the EKS Cluster
If you want to delete everything:
terraform destroy -auto-approve

------------------------------------------------------------------------------------------------------------------------------------
azurerm       <--It is the provider used in Terraform to manage Azure resources. The azurerm provider allows Terraform to provision 
                 and configure Azure infrastructure components such as Virtual Machines, Storage, Networking, and more.

Terraform Code for Azure VM
provider "azurerm" {
  features {}
}

# Define Resource Group
resource "azurerm_resource_group" "rg" {
  name     = "myResourceGroup"
  location = "East US"
}

# Define Virtual Network
resource "azurerm_virtual_network" "vnet" {
  name                = "myVNet"
  location            = azurerm_resource_group.rg.location
  resource_group_name = azurerm_resource_group.rg.name
  address_space       = ["10.0.0.0/16"]
}

# Define Subnet
resource "azurerm_subnet" "subnet" {
  name                 = "mySubnet"
  resource_group_name  = azurerm_resource_group.rg.name
  virtual_network_name = azurerm_virtual_network.vnet.name
  address_prefixes     = ["10.0.1.0/24"]
}

# Define Public IP
resource "azurerm_public_ip" "public_ip" {
  name                = "myPublicIP"
  location            = azurerm_resource_group.rg.location
  resource_group_name = azurerm_resource_group.rg.name
  allocation_method   = "Dynamic"
}

# Define Network Interface
resource "azurerm_network_interface" "nic" {
  name                = "myNIC"
  location            = azurerm_resource_group.rg.location
  resource_group_name = azurerm_resource_group.rg.name

  ip_configuration {
    name                          = "internal"
    subnet_id                     = azurerm_subnet.subnet.id
    private_ip_address_allocation = "Dynamic"
    public_ip_address_id          = azurerm_public_ip.public_ip.id
  }
}

# Define Virtual Machine
resource "azurerm_windows_virtual_machine" "vm" {
  name                = "myVM"
  resource_group_name = azurerm_resource_group.rg.name
  location            = azurerm_resource_group.rg.location
  size                = "Standard_B1s"
  admin_username      = "adminuser"
  admin_password      = "P@ssword1234!"  # Change this or use a secure method

  network_interface_ids = [azurerm_network_interface.nic.id]

  os_disk {
    caching              = "ReadWrite"
    storage_account_type = "Standard_LRS"
  }

  source_image_reference {
    publisher = "MicrosoftWindowsServer"
    offer     = "WindowsServer"
    sku       = "2019-Datacenter"
    version   = "latest"
  }
}

# Output Public IP
output "vm_public_ip" {
  value = azurerm_public_ip.public_ip.ip_address
}
-----------------
Data: In Terraform, the data block is used to fetch existing Azure resources, or derive dynamic values instead of creating new ones

Fetch an Existing Resource Group:
data "azurerm_resource_group" "existing_rg" {
  name = "MyExistingResourceGroup"
}
output "rg_location" {
  value = data.azurerm_resource_group.existing_rg.location
}

Get an Existing Virtual Network:
data "azurerm_virtual_network" "existing_vnet" {
  name                = "MyVNet"
  resource_group_name = "MyExistingResourceGroup"
}
output "vnet_address_space" {
  value = data.azurerm_virtual_network.existing_vnet.address_space
}

Get Available VM Sizes in a Region:
data "azurerm_compute_vm_sizes" "available_sizes" {
  location = "East US"
}
output "vm_sizes" {
  value = data.azurerm_compute_vm_sizes.available_sizes.sizes
}

Get an Existing Storage Account:
data "azurerm_storage_account" "existing_storage" {
  name                = "mystorageaccount"
  resource_group_name = "MyExistingResourceGroup"
}
output "storage_primary_endpoint" {
  value = data.azurerm_storage_account.existing_storage.primary_blob_endpoint
}
--------------------------------------------------------------------------------------------------------------
