## How to mount Blob storage as a file system with blobfuse
yum install blobfuse
sudo mount -t tmpfs -o size=16g tmpfs /mnt/ramdisk

Azure offers a vast range of services, but here are the most widely used categories and services based on their use cases:

1Ô∏è‚É£ Compute Services (Virtual Machines & Serverless)
üîπ Azure Virtual Machines (VMs) ‚Äì Run Windows/Linux VMs for applications
üîπ Azure Kubernetes Service (AKS) ‚Äì Managed Kubernetes for containerized apps
üîπ Azure Functions ‚Äì Serverless compute to run event-driven workloads
üîπ Azure App Service ‚Äì Deploy and manage web apps, APIs, and mobile backends
üîπ Azure Container Instances (ACI) ‚Äì Run containers without managing servers

2Ô∏è‚É£ Storage & Database Services
üîπ Azure Blob Storage ‚Äì Object storage for large-scale unstructured data
üîπ Azure Files ‚Äì Managed file shares in the cloud
üîπ Azure SQL Database ‚Äì Managed relational database with auto-scaling
üîπ Azure Cosmos DB ‚Äì NoSQL database for high-performance global apps
üîπ Azure Data Lake ‚Äì Big data storage for analytics workloads

3Ô∏è‚É£ Networking Services
üîπ Azure Virtual Network (VNet) ‚Äì Private networking in Azure
üîπ Azure Load Balancer ‚Äì Distribute traffic across multiple VMs
üîπ Azure Application Gateway ‚Äì Layer 7 load balancing with Web Application Firewall (WAF)
üîπ Azure ExpressRoute ‚Äì Private, dedicated connections to Azure
üîπ Azure VPN Gateway ‚Äì Secure hybrid cloud connectivity

4Ô∏è‚É£ Identity & Security
üîπ Azure Active Directory (Azure AD) ‚Äì Identity & access management for users and apps
üîπ Azure Key Vault ‚Äì Securely store and manage secrets, keys, and certificates
üîπ Microsoft Defender for Cloud ‚Äì Security posture management and threat protection
üîπ Azure Firewall ‚Äì Cloud-native firewall with threat intelligence
üîπ Azure DDoS Protection ‚Äì Protect apps from distributed denial-of-service attacks

5Ô∏è‚É£ DevOps & Monitoring
üîπ Azure DevOps ‚Äì CI/CD, source control, and agile project management
üîπ Azure Monitor ‚Äì Collect, analyze, and visualize logs and metrics
üîπ Azure Log Analytics ‚Äì Advanced logging and querying for insights
üîπ Azure Automation ‚Äì Automate processes, patching, and runbooks
üîπ Azure Application Insights ‚Äì Monitor and diagnose application performance

6Ô∏è‚É£ AI, Machine Learning & Analytics
üîπ Azure Machine Learning ‚Äì Build and deploy ML models
üîπ Azure Cognitive Services ‚Äì Pre-built AI models for vision, speech, and language
üîπ Azure Synapse Analytics ‚Äì Data warehousing and analytics at scale
üîπ Azure Databricks ‚Äì Managed Apache Spark for big data analytics
üîπ Azure Stream Analytics ‚Äì Real-time data processing

7Ô∏è‚É£ Internet of Things (IoT)
üîπ Azure IoT Hub ‚Äì Connect and manage IoT devices
üîπ Azure IoT Central ‚Äì Fully managed IoT solution
üîπ Azure Digital Twins ‚Äì Create digital replicas of real-world objects
üîπ Azure Time Series Insights ‚Äì Analyze IoT data in real-time

8Ô∏è‚É£ Hybrid & Multi-Cloud
üîπ Azure Arc ‚Äì Manage on-premises and multi-cloud environments
üîπ Azure Stack ‚Äì Run Azure services on-premises
üîπ Azure Backup ‚Äì Cloud-based backup solution
üîπ Azure Site Recovery ‚Äì Disaster recovery and business continuity

9Ô∏è‚É£ Messaging & Event-Driven Services
üîπ Azure Service Bus ‚Äì Enterprise-grade messaging between applications
üîπ Azure Event Grid ‚Äì Event-driven orchestration for applications
üîπ Azure Event Hubs ‚Äì Stream large-scale event data in real-time
üîπ Azure Notification Hubs ‚Äì Send push notifications to mobile devices

10Ô∏è‚É£ Management & Governance
üîπ Azure Policy ‚Äì Enforce organizational compliance policies
üîπ Azure Cost Management ‚Äì Monitor and optimize cloud spending
üîπ Azure Blueprints ‚Äì Deploy standardized cloud environments
üîπ Azure Resource Manager (ARM) ‚Äì Manage infrastructure as code (IaC)

Most Popular Use Cases for Azure Services
‚úÖ Web & Mobile Apps ‚Äì App Service, Functions, Cosmos DB
‚úÖ Big Data & Analytics ‚Äì Synapse, Databricks, Data Lake
‚úÖ Hybrid Cloud & Security ‚Äì Azure AD, Azure Arc, Key Vault
‚úÖ DevOps & Automation ‚Äì Azure DevOps, Terraform, ARM Templates
‚úÖ IoT & AI/ML ‚Äì IoT Hub, Machine Learning, Cognitive Services
-----------------------------------------------------------------------------------------------------------
In Azure, the equivalent of a GCP service account JSON file for authentication in Terraform is the Azure Service Principal (SP) 
with a Client Secret or Certificate.

Authentication Methods in Terraform for Azure
When using Terraform with Azure, you can authenticate using:

* Service Principal with Client Secret (Recommended for automation)
* Service Principal with Client Certificate
* Managed Identity (For Azure VMs & Cloud Shell)
* Azure CLI Authentication (For local development)
Steps to Authenticate Using a Service Principal JSON File
Step 1: Create a Service Principal in Azure
Run the following command in Azure CLI to create a Service Principal and save the credentials:

az ad sp create-for-rbac --name "terraform-sp" --role="Contributor" --scopes="/subscriptions/YOUR_SUBSCRIPTION_ID" --sdk-auth > azure-credentials.json
This will generate a JSON file with credentials like:

{
  "clientId": "xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx",
  "clientSecret": "xxxxxxxxxxxxxxxxxxxxxxxxxxxx",
  "subscriptionId": "xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx",
  "tenantId": "xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx",
  "activeDirectoryEndpointUrl": "https://login.microsoftonline.com",
  "resourceManagerEndpointUrl": "https://management.azure.com",
  "activeDirectoryGraphResourceId": "https://graph.windows.net/",
  "sqlManagementEndpointUrl": "https://management.core.windows.net:8443/",
  "galleryEndpointUrl": "https://gallery.azure.com/",
  "managementEndpointUrl": "https://management.core.windows.net/"
}
Step 2: Use the JSON File in Terraform
Modify your Terraform configuration to use the service principal credentials:

provider "azurerm" {
  features {}

  client_id       = jsondecode(file("azure-credentials.json"))["clientId"]
  client_secret   = jsondecode(file("azure-credentials.json"))["clientSecret"]
  tenant_id       = jsondecode(file("azure-credentials.json"))["tenantId"]
  subscription_id = jsondecode(file("azure-credentials.json"))["subscriptionId"]
}
2Ô∏è‚É£ Using a Service Principal with Client Certificate
Instead of using a client secret, you can use a certificate for authentication. This is more secure but requires managing a certificate.

provider "azurerm" {
  features {}

  client_id       = "xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx"
  tenant_id       = "xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx"
  subscription_id = "xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx"
  client_certificate_path = "/path/to/certificate.pem"
}
3Ô∏è‚É£ Using Azure CLI Authentication (For Local Development)
If you have already logged in using az login, Terraform can use your current Azure CLI credentials:

provider "azurerm" {
  features {}
  use_azuread_auth = true
}
Which Method Should You Use?
‚úÖ For automation (CI/CD, Terraform Cloud, remote execution) ‚Üí Use Service Principal with Client Secret.
‚úÖ For enhanced security ‚Üí Use Service Principal with Certificate.
‚úÖ For local development ‚Üí Use Azure CLI Authentication.
‚úÖ For Azure VM-based Terraform execution ‚Üí Use Managed Identity.
----------------------------------------------------------------------------------------------------------
To perform CI/CD (Continuous Integration and Continuous Deployment) using Azure DevOps, follow these steps:

1. Set Up Your Azure DevOps Project
Sign in to Azure DevOps ‚Äì Go to Azure DevOps and create a new project.
Create a Repository ‚Äì Navigate to Repos and create a Git repository to store your application code.

2. Create a CI/CD Pipeline
Step 1: Create a Build (CI) Pipeline
CI (Continuous Integration) ensures code is built and tested automatically.
Go to Azure Pipelines ‚Üí Pipelines ‚Üí New Pipeline.
Select "Use the classic editor" or "YAML" approach.
Choose your source control (Azure Repos, GitHub, etc.).
Select a template (e.g., ".NET Core", "Node.js", etc.).

Define the build steps:
Install dependencies (npm install, pip install -r requirements.txt, etc.).
Build the application (dotnet build, mvn package, etc.).
Run unit tests (dotnet test, pytest, etc.).
Publish build artifacts.

Example YAML pipeline for CI:
trigger:
  - main

pool:
  vmImage: 'ubuntu-latest'

steps:
  - task: UseNode@1
    inputs:
      version: '16.x'

  - script: |
      npm install
      npm run build
    displayName: 'Build and Install Dependencies'

  - script: npm test
    displayName: 'Run Tests'

  - task: PublishBuildArtifacts@1
    inputs:
      pathToPublish: 'dist'
      artifactName: 'drop'
Save and run the pipeline. This will trigger the build whenever code is pushed.

Step 2: Create a Release (CD) Pipeline
CD (Continuous Deployment) automates the deployment of the application.
Go to Azure Pipelines ‚Üí Releases ‚Üí New Release Pipeline.
Select a template (e.g., "Deploy to Azure Web App", "Kubernetes", "VM").
Choose "Artifacts" and select the output from the Build Pipeline.
Define deployment stages (Dev, Staging, Prod).
Add a deployment task (e.g., Kubernetes, Azure App Service, VM deployment).
Configure approvals if required.
Click Save and Deploy.

Example YAML CD pipeline for AKS:
trigger:
  - main

pool:
  vmImage: 'ubuntu-latest'

steps:
  - task: Kubernetes@1
    inputs:
      connectionType: 'Azure Resource Manager'
      azureSubscription: '<your-azure-subscription>'
      resourceGroupName: '<your-resource-group>'
      kubernetesCluster: '<your-aks-cluster>'
      namespace: 'default'
      command: 'apply'
      arguments: '-f k8s/deployment.yaml'
3. Configure CI/CD Triggers
Continuous Integration: Triggers automatically on code commits.
Continuous Deployment: Triggers when a build is completed.
4. Monitor and Debug
View pipeline runs in Azure DevOps ‚Üí Pipelines ‚Üí Runs.
Check logs for errors and fix them.
5. Secure Your Pipeline
Store secrets in Azure Key Vault.
Use Service Connections for authentication.
6. Extend and Optimize
Add SonarCloud for code quality checks.
Implement Blue-Green Deployment for safer releases.
Use Terraform for infrastructure as code.
üöÄ Now you have a fully automated CI/CD pipeline using Azure DevOps! Do you need a specific setup like AKS deployment or Docker integration?

------------------
how to use azure pipeline to deploy php application into apache

To deploy a PHP application to an Apache server using Azure Pipelines, follow these steps:
1. Set Up Your Azure DevOps Project
Sign in to Azure DevOps ‚Üí Create a new project.
Create a Repository ‚Üí Push your PHP application code to Azure Repos (or GitHub).

2. Configure Your Apache Server
Make sure your Apache server (on a VM or on-premises) is:
Running Apache and PHP (sudo apt install apache2 php on Ubuntu).
Has SSH access enabled for deployment.
The web root directory is /var/www/html or a custom path.

3. Create an Azure Pipeline for CI/CD
We will set up a pipeline that:
Installs dependencies (if required).
Copies the PHP files to the Apache web root using SSH.
Option 1: Use YAML Pipeline (Recommended)
In Azure DevOps ‚Üí Go to Pipelines ‚Üí New Pipeline.
Select your source repo.
Choose "Starter Pipeline" and replace it with the YAML below.
Modify remoteServer (your VM's IP/hostname) and sshUser.

trigger:
- main  # Runs pipeline on code push to main branch

pool:
  vmImage: 'ubuntu-latest'

steps:
- task: SSH@0
  inputs:
    sshEndpoint: 'my-ssh-service-connection'  # Create an SSH service connection in Azure DevOps
    runOptions: 'commands'
    commands: |
      sudo rm -rf /var/www/html/*
    readyTimeout: '20000'

- task: CopyFilesOverSSH@0
  inputs:
    sshEndpoint: 'my-ssh-service-connection'
    sourceFolder: '$(Build.SourcesDirectory)'  # Source code directory
    contents: '**'  # Copy all files
    targetFolder: '/var/www/html'  # Destination folder on Apache server
    cleanTargetFolder: true  # Clean existing files before copying

- task: SSH@0
  inputs:
    sshEndpoint: 'my-ssh-service-connection'
    runOptions: 'commands'
    commands: |
      sudo systemctl restart apache2
    readyTimeout: '20000'

4. Set Up an SSH Service Connection in Azure DevOps
Since we're using SSH deployment, you need to configure an SSH service connection:

Go to Azure DevOps ‚Üí Project Settings ‚Üí Service connections.
Click New service connection ‚Üí Select SSH.
Enter:
Host: Your VM's public IP (or domain).
Port: Default is 22.
Username: SSH user (e.g., ubuntu or root).
Password or Private Key (Use SSH key authentication if possible).
Click Save and use the name my-ssh-service-connection in your YAML.

5. Run and Verify Deployment
Commit & push your code to main branch.
Go to Azure DevOps ‚Üí Pipelines and run the pipeline.
If successful, check http://your-server-ip/ to see your PHP app running.

6. Optional Enhancements
Database Migration: Add MySQL setup (mysql -u root -p < db.sql).
CI Testing: Run PHP Unit Tests before deploying.
Rolling Deployment: Deploy to a staging server first, then to production.
----------------------------------------------------------------------------------------------------------------------------

# Azure CLI 2.0 Cheatsheet
Azure CLI 2.0 cheatsheet for Login, Resources, VMs, Resource groups, Storage, Batch, and Containers.

## Logging in
### Login with web
az login

### Login in CLI
```
az login -u myemail@address.com
```

### List accounts
```
az account list
```

### Set subscription
```
az account set --subscription "xxx"
```

## Listing locations and resources / general

### List all locations
```
az account list-locations
```

### List all my resource groups
```
az resource list
```

### Get what version of the CLI you have
```
azure --version
```

### Get help
```
azure help
```

## Creating a basic VM / Resource Group / Storage Account

### Get all available VM sizes
```
az vm list-sizes --location eastus
```

### Get all available VM images for Windows and Linux
```
az vm image list --output table
```

### Create a Linux VM
```
az vm create --resource-group myResourceGroup --name myVM --image ubuntults
```

### Create a Windows VM
```
az vm create --resource-group myResourceGroup --name myVM --image win2016datacenter
```

### Create a Resource group
```
az group create --name myresourcegroup --location eastus
```

### Create a Storage account.
```
az storage account create -g myresourcegroup -n mystorageaccount -l eastus --sku Standard_LRS
```

## DELETING A RESOURCE GROUP

### Permanetly deletes a resource group
```
az group delete --name myResourceGroup
```

## Managing VM's

### List your VMs
```
az vm list
```

### Start a VM
```
az vm start --resource-group myResourceGroup --name myVM
```

### Stop a VM
```
az vm stop --resource-group myResourceGroup --name myVM
```

### Deallocate a VM
```
az vm deallocate --resource-group myResourceGroup --name myVM
```

### Restart a VM
```
az vm restart --resource-group myResourceGroup --name myVM
```

### Redeploy a VM
```
az vm redeploy --resource-group myResourceGroup --name myVM
```

### Delete a VM
```
az vm delete --resource-group myResourceGroup --name myVM
```

### Create image of a VM
```
az image create --resource-group myResourceGroup --source myVM --name myImage
```

### Create VM from image
```
az vm create --resource-group myResourceGroup --name myNewVM --image myImage
```

### List VM extensions
```
az vm extension list --resource-group azure-playground-resources --vm-name azure-playground-vm
```

### Delete VM extensions
```
az vm extension delete --resource-group azure-playground-resources --vm-name azure-playground-vm --name bootstrapper
```

## Managing Batch Account

### Create a Batch account.
```
az batch account create -g myresourcegroup -n mybatchaccount -l eastus
```

### Create a Storage account.
```
az storage account create -g myresourcegroup -n mystorageaccount -l eastus --sku Standard_LRS
```

### Associate Batch with storage account.
```
az batch account set -g myresourcegroup -n mybatchaccount --storage-account mystorageaccount
```

We can now authenticate directly against the account for further CLI interaction.

```
az batch account login -g myresourcegroup -n mybatchaccount
```

### Display the details of our created account.
```
az batch account show -g myresourcegroup -n mybatchaccount
```

### Create a new application.
```
az batch application create --resource-group myresourcegroup --name mybatchaccount --application-id myapp --display-name "My Application"
```

### Add zip files to application
```
az batch application package create --resource-group myresourcegroup --name mybatchaccount --application-id myapp --package-file my-application-exe.zip --version 1.0
```

### Assign the application package as the default version.
```
az batch application set --resource-group myresourcegroup --name mybatchaccount --application-id myapp --default-version 1.0
```

### Retrieve a list of available images and node agent SKUs.
```
az batch pool node-agent-skus list
```

### Create new Linux pool with VM config
```
az batch pool create \
    --id mypool-linux \
    --vm-size Standard_A1 \
    --image canonical:ubuntuserver:16.04.0-LTS \
    --node-agent-sku-id ‚Äúbatch.node.ubuntu 16.04‚Äù
```

### Now let's resize the pool to start up some VMs.
```
az batch pool resize --pool-id mypool-linux --target-dedicated 5
```

### We can check the status of the pool to see when it has finished resizing.
```
az batch pool show --pool-id mypool-linux
```

### List the compute nodes running in a pool.
```
az batch node list --pool-id mypool-linux
```

If a particular node in the pool is having issues, it can be rebooted or reimaged.
A typical node ID will be in the format 'tvm-xxxxxxxxxx_1-<timestamp>'.
```
az batch node reboot --pool-id mypool-linux --node-id tvm-123_1-20170316t000000z
```

### Re-allocate work to another node.
```
az batch node delete \
    --pool-id mypool-linux \
    --node-list tvm-123_1-20170316t000000z tvm-123_2-20170316t000000z \
    --node-deallocation-option requeue
```

### Create a new job to encapsulate the tasks that we want to add.
```
az batch job create --id myjob --pool-id mypool
```

### Add tasks to the job.
 ‚Ä¶where <shell> is your preferred shell for execution (/bin/sh, /bin/bash, /bin/ksh etc.), and /path/to/script.sh is, of course, the full path of the shell script you‚Äôre invoking to get things started.

```
az batch task create --job-id myjob --task-id task1 --application-package-references myapp#1.0 --command-line "/bin/<shell> -c /path/to/script.sh"
```

### Add many tasks at once
```
az batch task create --job-id myjob --json-file tasks.json
```

Now that all the tasks are added - we can update the job so that it will automatically be marked as completed once all the tasks are finished.

```
az batch job set --job-id myjob --on-all-tasks-complete terminateJob
```

### Monitor the status of the job.
```
az batch job show --job-id myjob
```

### Monitor the status of a task.
```
az batch task show --job-id myjob --task-id task1
```

### Delete a job
```
az batch job delete --job-id myjob
```

## Managing Containers

If you HAVE AN SSH run this to create an Azure Container Service Cluster (~10 mins)

```
az acs create -n acs-cluster -g acsrg1 -d applink789
```

If you DO NOT HAVE AN SSH run this to create an Azure Container Service Cluster (~10 mins)

```
az acs create -n acs-cluster -g acsrg1 -d applink789 --generate-ssh-keys
```

### List clusters under your whole subscription
```
az acs list --output table
```

### List clusters in a resource group
```
az acs list -g acsrg1 --output table
```

### Display details of a container service cluster
```
az acs show -g acsrg1 -n acs-cluster --output list
```

### Scale using ACS
```
az acs scale -g acsrg1 -n acs-cluster --new-agent-count 4
```

### Delete a cluster
```
az acs delete -g acsrg1 -n acs-cluster
```
