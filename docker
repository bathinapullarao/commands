#stateless application is one that neither reads nor stores information about its state from one time that it is run to the next.
gcloud auth login
gcloud config set project [PROJECT_ID]
gcloud services enable containerregistry.googleapis.com
gcloud auth configure-docker     <--Authenticate Docker with GCR
docker login -u _json_key --password-stdin https://gcr.io  <--Verify Authentication
docker tag myapp:latest gcr.io/[PROJECT_ID]/myapp:latest
docker push gcr.io/[PROJECT_ID]/myapp:latest
gcloud container images list
-------------------------------------------------------------------------------------
aws configure  <--You will be prompted to enter:AWS Access Key ID-->AWS Secret Access Key-->Default region (e.g., us-east-1)-->Output format (leave as json or none)
aws ecr get-login-password --region us-east-1 | docker login --username AWS --password-stdin [AWS_ACCOUNT_ID].dkr.ecr.[REGION].amazonaws.com
aws ecr create-repository --repository-name myapp  <--Create an ECR Repository
docker tag myapp:latest [AWS_ACCOUNT_ID].dkr.ecr.[REGION].amazonaws.com/myapp:latest
docker push [AWS_ACCOUNT_ID].dkr.ecr.[REGION].amazonaws.com/myapp:latest
aws ecr list-images --repository-name myapp
docker pull [AWS_ACCOUNT_ID].dkr.ecr.[REGION].amazonaws.com/myapp:latest
---------------------------------------------------------------------------------------
# Dockerfile instructions 
FROM,  <-- FROM php:7.3-cli as php-cli, Specifies the base image for the container. 
           Every Dockerfile must start with a FROM instruction.
ARG,   <-- Defines build-time variables (values can be passed via docker build --build-arg).
           Used only during the build process (not available in the final container).
           eg:ARG APP_VERSION=1.0
ENV,   <-- Defines environment variables available inside the container. These persist when the container is running.
           eg: ENV APP_ENV=production
           Both ARG and ENV can store values inside varibles but ENV varible value even can available after creating container.
WORKDIR, <-- Sets the working directory for subsequent RUN, CMD, ENTRYPOINT, COPY, and ADD instructions.
             eg: WORKDIR /app
RUN,  <--These commands get executed once at build time and get written into your Docker image as a # new layer.
         eg:RUN apt-get update && apt-get install -y curl
CMD,  <--sets default command and/or parameters, which can be overwritten from command line when docker container runs.
         eg: CMD ["python", "app.py"] 
             CMD python app.py
ENTRYPOINT, <--If ENTRYPOINT is specified, CMD will provide default arguments to it. If no ENTRYPOINT is defined, CMD will be the command that is executed when the container starts.
          ENTRYPOINT ["python", "app.py"]
          CMD ["--help"]
          This sets python app.py as the base command.
          If you run the container without arguments, it will execute python app.py --help
ADD,  <--Copies files from the host system into the container. command is used to copy files/directories into a Docker image
          ADD source(even URL) destination
COPY, <-- COPY <src> … <dest> 
EXPOSE,  <--Informs Docker that the container listens on a specific port.
            This does not automatically publish the port; -p must be used when running the container.
PUBLISH,  <-- This is used with docker run -p to map container ports to the host.
              -p 8080  Publish individual port at eg(docker run -d -p 8080 an_image)
              -P, --publish-all  Publish all exposed ports to random ports
           1) If you specify neither EXPOSE nor -p, the service in the container will only be accessible from inside the container itself.
           2) If you EXPOSE a port, the service in the container is not accessible from outside Docker, but from inside other Docker containers. So this is good for inter-container communication.
           3) If you EXPOSE and -p a port, the service in the container is accessible from anywhere, even outside Docker.
LABEL maintainer="Bathina Pullarao"              
USER, <--Sets the user under which the container will run.
         eg: USER appuser
VOLUME, <--Defines a mount point for persistent storage.
           eg: VOLUME /data
           docker run -v /host/path:/data myapp
STOPSIGNAL, and ONBUILD.

eg:
FROM centos:centos7
RUN yum update -y \
    && yum install -y \
    epel-release \
    gcc \
    git \
    httpd \
    net-tools \
    nmap-ncat \
    openssh-clients \
    psacct \
    sysstat \
    tcpdump \
    telnet \
    traceroute \
    unzip \
    wget
    # Ref:https://www.geeksforgeeks.org/apt-get-command-in-linux-with-examples/#:~:text=%E2%80%93no%2Dinstall%2Drecommends%20%3A,as%20a%20dependency%20to%20install.&text=%2Dd%20or%20%E2%80%93download%2Donly,not%20unpack%20or%20install%20them.
    --no-install-recommends      <--By passing this option, the user lets apt-get know not to consider recommended packages as a dependency to install.
    -d or –download-only         <-- By passing this option, the user specifies that apt-get should only retrieve the packages, and not unpack or install them.
    -y or –yes or –assume-yes    <-- it may sometimes prompt the user for a yes/no. With this option, it is specified that it should assume ‘yes’ for all prompts
RUN yum install -y http://---.rpm
WORKDIR /tmp
RUN ssh-keyscan -t rsa domainname > /root/.ssh/known_hosts    <--accept domain
CMD ["/usr/sbin/httpd","-DFOREGROUND"]
-------------------------------------------------------------------------------------------------
# Use a base image
FROM ubuntu:latest

# Define a build-time variable
ARG APP_VERSION=1.0

# Set an environment variable
ENV APP_HOME=/app \
    APP_VERSION=$APP_VERSION

# Set the working directory inside the container
WORKDIR $APP_HOME

# Add a file from a remote URL or local tar archive (ADD can also extract archives)
ADD https://raw.githubusercontent.com/docker/cli/main/README.md /app/remote_file.txt

# Copy files from the host machine to the container
COPY app_source/ /app/

# Install dependencies (example: install curl)
RUN apt-get update && apt-get install -y curl

# Expose a port (for documentation purposes)
EXPOSE 8080

# Publish a port (not a valid Dockerfile instruction, used at runtime with `-p`)
# PUBLISH 8080:8080  (not valid in Dockerfile)

# Set a non-root user (assumes user 'appuser' exists)
USER root

# Define a volume for persistent data
VOLUME /app/data

# Default command to run the container (overridable)
CMD ["echo", "Hello from Dockerfile!"]

# Entry point script (used for executing the main process)
ENTRYPOINT ["/bin/bash"]
-----------------------------------------------------------------------------------------------------

#Simple commands
docker pull docker.elastic.co/elasticsearch/elasticsearch:7.9.0   <--pull the image from registry
docker info                                  <-- gives information about the docker setup on your machine/vm
docker rename big_hamilton big_hamilton_v1   <-- remane docker container
docker rm CONTAINER_NAME                     <-- Delete a Container
docker rm `docker ps --no-trunc -aq`         <-- Removing all the Containers
docker pause CONTAINER_NAME                  <-- Pause a Container
docker unpause CONTAINER_NAME                <-- UnPaise a Paused Container
docker logs -f [CONTAINER_NAME]              <-- -f: Follows the logs in real-time.View Logs of a Running Container
docker logs [CONTAINER_NAME]                 <-- get a list of commands executed in the container.
docker ps -a                                 <-- List of docker containers running
docker inspect CONTAINER_NAME                <-- Inspect a Container  Output will be a JSON file.
docker start [CONTAINER_NAME]                <-- Start a Stopped Container
docker stop [CONTAINER_NAME]                 <-- Stop a Running Container
docker restart [CONTAINER_NAME]              <-- Restart a Container
docker attach CONTAINER_NAME                 <-- Enter the Shell of a Started Container
sudo docker run -i -t debian /bin/bash       <-- Create a Container and enter its shell, -i -t (interactive session with a tty attached)
docker run -h CONTAINER1 -i -t debian /bin/bash                 <-- -h parameter to specify a container name
docker run -h CONTAINER2 -i -t --net="bridge" debian /bin/bash  <-- Create a container with a Networking mode
docker run --name my-custom-nginx-container -v /host/path/nginx.conf:/etc/nginx/nginx.conf:ro -d nginx   <-- Attache volume in readonly, remove :ro to write
docker run -d -p 8080:80 --name myapp nginx  <-- -d: Runs the container in detached mode (background).
                                                 -p 8080:80: Maps port 8080 on the host to port 80 in the container.
                                                 --name myapp: Assigns a custom name to the container.
                                                 nginx: The image to use.
#To create a image form dockerfile,  you should execute below command from the folder which contain dockerfile
docker build -t myapp:latest .  <-- -t myapp:latest: Tags the image with a name and version.
                                    .: Uses the current directory as the build context.
docker tag myapp:latest myrepo/myapp:v1 <--Tag an Image
docker push myrepo/myapp:v1     <-- Push an Image to Docker Hub

#prune
docker image prune -a           <--Remove Unused Images
docker container prune          <--Remove All Stopped Containers
docker volume prune             <--Remove All Unused Volumes
docker system prune -a          <--Remove Everything (Images, Containers, Volumes, Networks)

DOCKER_BUILDKIT=1 docker build --secret id=ssh,src=~/.ssh/id_rsa   --build-arg GIT_BRANCH=release   -f Dockerfile   -t php-apache:1.0 .
docker images  <--List Images
docker rmi ubuntu:latest <--Remove an Image
# Command to login docker container
docker exec -it 6a4f2dba71c2 /bin/bash   <--Execute a Command Inside a Running Container, bash: Opens a terminal inside the container.
# docker cp
* docker cp containerId:/file/path/in/container/file /host/local/path/file
* docker cp /host/local/path/file containerId:/file/path/in/container/file

#docker compose
docker-compose -f mongo.yaml up -d    <--Runs services in detached mode.
docker-compose -f mongo.yaml down     <--Stops and removes all containers.
docker-compose logs -f                <--View Logs
docker-compose up --build -d          <--Rebuild and Restart Services

#volume
docker volume ls                      <--docker volume ls
docker volume create mydata           <--Create a Volume
docker volume rm mydata               <--Remove a Volume

#docker network
docker network ls                     <--List Networks
docker network create mynetwork       <--Create a Network
docker network connect mynetwork myapp <--Connect a Container to a Network
docker network rm mynetwork           <--docker network rm mynetwork
#use network
docker run -d \                             <-- d demen
-p 27017:27017 \                            <-- p vmport:containerport
-e MONGO_INITDB_ROOT_USERNAME=admin \       <-- e environmnet varible
-e MONGO_INITDB_ROOT_PASSWORD=password \
--net mongo-network \                       <-- net network
--name mongodb \                            <-- 
mongo
